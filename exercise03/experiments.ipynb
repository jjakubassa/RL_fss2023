{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exercise03 import QNet, MC_func_approx, evaluate_greedy_policy, gym_video, DQN\n",
    "import gymnasium as gym\n",
    "from tqdm.notebook import trange\n",
    "import torch\n",
    "import datetime\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cartpole DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hyperparameters = {\n",
    "    \"epsilon\": 0.7,\n",
    "    \"nr_episodes\": 10_000,\n",
    "    \"max_t\": 1000,\n",
    "    \"gamma\": 0.99,\n",
    "    \"replay_buffer_size\": 1000,\n",
    "    \"warm_start_steps\": 500,\n",
    "    \"sync_rate\": 128,\n",
    "    \"replay_buffer_size\": 1000,\n",
    "    \"train_frequency\": 8,\n",
    "    \"batch_size\": 128,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparations\n",
    "cartpole_env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "cartpole_observation_space_size = cartpole_env.observation_space.shape[0]\n",
    "cartpole_nr_actions = cartpole_env.action_space.n\n",
    "cartpole_qnet = QNet(cartpole_observation_space_size, cartpole_nr_actions, 8, 2)\n",
    "cartpole_optimizer = torch.optim.RMSprop(cartpole_qnet.parameters(), lr=1e-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train policy with DQN for 10000 episodes using at most 1000 steps, gamma = 0.99, epsilon = 0.7, replay buffer size = 1000, sync rate = 128, warm starting steps for filling the replay buffer = 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DQN Training: 100%|██████████| 10000/10000 [07:20<00:00, 22.68episodes/s, e return=20.30, e length=20.30]\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "DQN_carpole_policy = DQN(\n",
    "    cartpole_qnet,\n",
    "    cartpole_env,\n",
    "    cartpole_optimizer,\n",
    "    **hyperparameters,\n",
    "    output_path=\"output/\",\n",
    ").act_greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean episode reward from DQN on cartpole policy:  9.44\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "print(\n",
    "    \"Mean episode reward from DQN on cartpole policy: \",\n",
    "    evaluate_greedy_policy(cartpole_env, DQN_carpole_policy, 100, 4_000),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "video_name = f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}-DQN-{cartpole_env.spec.id}\"\n",
    "gym_video(DQN_carpole_policy, cartpole_env, video_name, 5000, output_path=\"output/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <video width=\"420\" height=\"320\" controls>\n",
       "        <source src=\"output/2023-04-20_11-26-13-DQN-CartPole-v1-episode-0.mp4\" type=\"video/mp4\">\n",
       "    </video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(f\"\"\"\n",
    "    <video width=\"420\" height=\"320\" controls>\n",
    "        <source src=\"output/{video_name}-episode-0.mp4\" type=\"video/mp4\">\n",
    "    </video>\n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mountain Car DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hyperparameters = {\n",
    "    \"epsilon\": 0.05,\n",
    "    \"nr_episodes\": 400,\n",
    "    \"max_t\": 4000,\n",
    "    \"gamma\": 0.99,\n",
    "    \"replay_buffer_size\": 50_000,\n",
    "    \"warm_start_steps\": 500,\n",
    "    \"sync_rate\": 128,\n",
    "    \"train_frequency\": 8,\n",
    "    \"batch_size\": 128,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare\n",
    "mountaincar_env = gym.make(\n",
    "    \"MountainCar-v0\",\n",
    "    render_mode=\"rgb_array\",\n",
    "    max_episode_steps=hyperparameters[\"max_t\"],\n",
    ")\n",
    "mountaincar_observation_space_size = mountaincar_env.observation_space.shape[0]\n",
    "mountaincar_nr_actions = mountaincar_env.action_space.n\n",
    "mountaincar_qnet = QNet(\n",
    "    mountaincar_observation_space_size,\n",
    "    mountaincar_nr_actions,\n",
    "    8,\n",
    "    2,\n",
    ")\n",
    "mountaincar_optimizer = torch.optim.RMSprop(mountaincar_qnet.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train policy with DQN for 400 episodes using at most 4000 steps, gamma = 0.99, epsilon = 0.05, replay buffer size = 5000, sync rate = 128, warm starting steps for filling the replay buffer = 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DQN Training: 100%|██████████| 400/400 [16:53<00:00,  2.53s/episodes, e return=-560.90, e length=560.90]   \n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "DQN_mountaincar_policy = DQN(\n",
    "    mountaincar_qnet,\n",
    "    mountaincar_env,\n",
    "    mountaincar_optimizer,\n",
    "    **hyperparameters,\n",
    "    output_path=\"output/\"\n",
    ").act_greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean episode reward from MC_func_approx on mountaincar policy:  -279.3\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "print(\n",
    "    \"Mean episode reward from MC_func_approx on mountaincar policy: \",\n",
    "    evaluate_greedy_policy(mountaincar_env, DQN_mountaincar_policy, 10, 4_000),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonas/mambaforge/envs/MMDS/lib/python3.10/site-packages/gymnasium/wrappers/record_video.py:79: UserWarning: \u001b[33mWARN: Overwriting existing videos at /Users/jonas/sciebo/MMDS/RL/exercise03/output folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# Visualize\n",
    "video_name = f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}-DQN-{mountaincar_env.spec.id}\"\n",
    "gym_video(\n",
    "    DQN_mountaincar_policy,\n",
    "    mountaincar_env,\n",
    "    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}-DQN-{mountaincar_env.spec.id}\",\n",
    "    5000,\n",
    "    output_path=\"output/\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <video width=\"420\" height=\"320\" controls>\n",
       "        <source src=\"output/2023-04-20_10-49-46-DQN-MountainCar-v0-episode-0.mp4\" type=\"video/mp4\">\n",
       "    </video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(f\"\"\"\n",
    "    <video width=\"420\" height=\"320\" controls>\n",
    "        <source src=\"output/{video_name}-episode-0.mp4\" type=\"video/mp4\">\n",
    "    </video>\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MMDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
